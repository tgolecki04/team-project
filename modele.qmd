---
title: "Wczesne Wykrywanie Ryzyka Zawału Serca"
subtitle: "Modele Predykcyjne"
format: html
editor: visual
---

## Wstęp

Modele predykcyjne stanowią kluczowy element analityki danych i sztucznej inteligencji. Pozwalają przewidywać przyszłe zdarzenia, klasyfikować obserwacje oraz identyfikować ukryte zależności w danych. W praktyce biznesowej i naukowej stosuje się wiele podejść modelowania – od klasycznych metod statystycznych, przez algorytmy uczenia maszynowego, aż po zaawansowane architektury sieci neuronowych.\

Na tej podstronie przedstawiamy trzy popularne i często stosowane techniki modelowania predykcyjnego: **regresję logistyczną**, **las losowy** oraz **sieci neuronowe (NN)**. Każda z nich opiera się na innym mechanizmie działania i oferuje różne możliwości modelowania złożoności danych.

W rozważanym zbiorze danych posiadamy zmienną predykcyjną `Ten_Year_CHD`, która jest zmienną binarną - przyjmuje wartości 0 lub 1. Wartość 0 oznacza brak zagrożenia wystąpienia choroby wieńcowej w ciągu 10 najbliższych lat, natomiast zmienna przyjmująca wartość 1, oznacza ryzyko wystąpienia choroby. Struktura naszych danych mówi jasno w jaki sposób powinniśmy tworzyć nasze modele. Zajmiemy się problemem klasyfikacji, starając się każdemu z pacjentów określić grupę do której należy - potencjalne ryzyko lub jego brak. Dodatkowo tworząc model oparty o architekturę sieci neuronowej rozszerzymy zakres naszej klasyfikacji z binarnej na wieloczynnikową. Zanim omówimy każdy z modeli osobno, chcemy poruszyć kwestię uczenia maszynowego oraz pojęć z tym związanym w celu lepszego przedstawienia problemu oraz ułatwienia zrozumienia architektury stworzonych modeli. Modele te zostały stworzone w języku programowania `python` przy użyciu bilbiotek takich jak:

-   Scikit-learn

-   Pandas

-   Numpy

-   Pytorch

## Machine Learning

### Wyjaśnienie

**Machine Learning (ML), czyli uczenie maszynowe**, to dziedzina sztucznej inteligencji, która umożliwia komputerom **uczenie się na podstawie danych** i podejmowanie decyzji bez konieczności ręcznego programowania każdej reguły.\

Model ML analizuje dostarczone mu przykłady, identyfikuje wzorce oraz uczy się przewidywać przyszłe zdarzenia, klasyfikować obiekty czy podejmować optymalne decyzje.

### Diagram

![](images/article/picture_4.png){fig-align="center" width="683"}

### Poddziedziny

#### Uczenie nadzorowane (Supervised Learning)

##### Wyjaśnienie

Model uczy się na danych, dla których znamy prawidłową odpowiedź (tzw. etykietę).\
Celem jest przewidywanie wyników dla nowych, nieznanych danych.

##### Przykłady

-   Klasyfikacja (np. wykrywanie spamu, diagnoza chorób),

-   Regresja (np. prognoza cen, przewidywanie popytu).

#### Uczenie nienadzorowane (Unsupervised Learning)

##### Wyjaśnienie

Model szuka struktury w danych bez etykiet. Celem jest odkrywanie ukrytych zależności, grup lub reprezentacji danych.

##### Przykłady

-   Klasteryzacja

-   Redukcja Wymiarów

#### Uczenie półnadzorowane (Semi-Supervised Learning)

##### Wyjaśnienie

Połączenie uczenia nadzorowanego i nienadzorowanego – model uczy się na niewielkiej ilości danych z etykietami i dużej ilości danych bez nich.

#### Uczenie ze wzmocnieniem (Reinforcement Learning)

##### Wyjaśnienie

Agent uczy się poprzez interakcję z otoczeniem, otrzymując nagrody lub kary.\

Celem jest opracowanie strategii maksymalizującej długoterminową nagrodę.

##### Przykłady

-   Gry

-   Sterowanie robotami

-   Autonomiczne pojazdy

#### Uczenie głębokie (Deep Learning)

Model wykorzystuje sieci składające się z wielu warstw przetwarzających dane. Dzięki takiemu zastosowaniu jesteśmy w stanie znajdować głębokie wzorce i zależności, które nie są możliwe do zauważenia stosując pozostałe architektury modeli. Sieć nazywamy "głęboką" ponieważ ma wiele poziomów. Wyróżniamy:

-   warstwę wejściową

-   wiele warstw ukrytych

-   warstwę wyjściową

Każda warstwa przetwarza dane w inny sposób co pozwala na połączenie skomplikowanych obliczeń i wykrycie ważnych oraz skomplikowanych zależności.

##### Przykłady

**CNN (Convolutional Neural Networks)** – do obrazów, wideo, sygnałów.

**RNN (Recurrent Neural Networks)**, **LSTM**, **GRU** – do sekwencji, tekstu, sygnałów czasowych.

**Transformers** – obecny standard w NLP, analizie języka, obrazu i wielu innych dziedzinach.

<div>

![](images/article/picture_2.png){style="margin-top: 25px;" fig-align="center"}

</div>
